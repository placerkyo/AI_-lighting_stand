{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNMhpXONUJtaTTlbCeMNei"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"l4Ussh0NyVCm"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import inspect\n","from PIL import Image"],"metadata":{"id":"EU0KdDnAybTm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","n_people = 6\n","n_data = 0\n","image_size = 32\n","\n","t_train = np.array([])\n","for n in range(n_people): #人数分の顔画像についてのループ\n","    if n==3: continue\n","    files = glob.glob('drive/My Drive/Colab Notebooks/創造性/data/Identification_persons/' + str(n) + '/*')\n","    for i in range(len(files)):\n","        img = Image.open(files[i])\n","        img = img.resize((image_size, image_size)) #image_size×image_size 画素に変換\n","        data = np.array(img) # numpy 形式に変換する\n","        data = data.reshape([-1, image_size, image_size])\n","        #print(data)\n","\n","        if i==0 and n==0:\n","            x_train = data\n","        else :\n","            x_train = np.append(x_train, data, axis=0) #行ベクトルを連結する\n","\n","        t_train = np.hstack((t_train, np.array([n]))) #行ベクトルを連結する\n","    print(t_train.shape[0] - n_data)\n","    n_data = t_train.shape[0]\n","\n","#X = np.asarray(X_list).reshape(-1,imY*imX)\n","#各配列の大きさを確認する\n","print(x_train.shape)\n","print(t_train.shape)"],"metadata":{"id":"LQHQ1AelVv6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        self.x_train = x_train.reshape(-1, 1, image_size, image_size).astype('float32') / 255\n","        self.t_train = t_train\n","        print(self.x_train.shape)\n","\n","    def __len__(self):\n","        return self.x_train.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(self.t_train[idx], dtype=torch.long)\n","\n","\n","trainval_data = train_dataset(x_train, t_train)"],"metadata":{"id":"eMs1_1DUmCiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","\n","val_size = 500\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")"],"metadata":{"id":"gBTINrvmmSKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","import numpy as np\n","import torch\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","class Conv(nn.Module):\n","    def __init__(self, filter_shape, function=lambda x: x, stride=(1, 1), padding=0):\n","        super().__init__()\n","        # Heの初期値\n","        fan_in = filter_shape[1] * filter_shape[2] * filter_shape[3]\n","        # filter_shape: (出力チャンネル数)x(入力チャンネル数)x(縦の次元数)x(横の次元数)\n","        fan_out = filter_shape[0] * filter_shape[2] * filter_shape[3]\n","\n","        self.W = nn.Parameter(torch.tensor(rng.uniform(\n","                        -np.sqrt(6/fan_in),\n","                        np.sqrt(6/fan_in),\n","                        size=filter_shape\n","                    ).astype('float32')))\n","\n","        # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n","        self.b = nn.Parameter(torch.tensor(np.zeros((filter_shape[0]), dtype='float32')))\n","        self.function = function\n","        self.stride = stride\n","        self.padding = padding\n","        \n","    def forward(self, x):\n","        u = F.conv2d(x, self.W, bias=self.b, stride=self.stride, padding=self.padding)\n","        return self.function(u)\n","\n","\n","\n","class Pooling(nn.Module):\n","    def __init__(self, ksize=(2, 2), stride=(2, 2), padding=0):\n","        super().__init__()\n","        self.ksize = ksize\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        return F.avg_pool2d(x, kernel_size=self.ksize, stride=self.stride, padding=self.padding)\n","\n","\n","class Flatten(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)\n","\n","\n","class Dense(nn.Module):\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):\n","        super().__init__()\n","        # He Initialization\n","        # in_dim: 入力の次元数、out_dim: 出力の次元数              \n","        self.W = nn.Parameter(torch.tensor(rng.uniform(\n","                        -np.sqrt(6/in_dim),\n","                        np.sqrt(6/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","\n","    def forward(self, x):\n","        return self.function(torch.matmul(x, self.W) + self.b)\n","\n","class Activation(nn.Module):\n","    def __init__(self, function=lambda x: x):\n","        super().__init__()\n","        self.function = function\n","\n","    def __call__(self, x):\n","        return self.function(x)\n","\n","class BatchNorm(nn.Module):\n","    def __init__(self, shape, epsilon=np.float32(1e-5)):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.tensor(np.ones(shape, dtype='float32')))\n","        self.beta = nn.Parameter(torch.tensor(np.zeros(shape, dtype='float32')))\n","        self.epsilon = epsilon\n","\n","    def forward(self, x):\n","        mean = torch.mean(x, (0, 2, 3), keepdim=True)\n","        std = torch.std(x, (0, 2, 3), keepdim=True)\n","        x_normalized = (x - mean) / (std**2 + self.epsilon)**0.5\n","        return self.gamma * x_normalized + self.beta\n","\n","class Dropout(nn.Module):\n","    def __init__(self, dropout_ratio=0.5):\n","        super().__init__()\n","        self.dropout_ratio = dropout_ratio\n","        self.mask = None\n","\n","    def forward(self, x):\n","        # 学習時はdropout_ratio分だけ出力をシャットアウト\n","        if self.training:\n","            self.mask = torch.rand(*x.size()) > self.dropout_ratio\n","            return x * self.mask.to(x.device)\n","        # 推論時は出力に`1.0 - self.dropout_ratio`を乗算することで学習時の出力の大きさに合わせる\n","        else:\n","            return x * (1.0 - self.dropout_ratio)\n","\n","\n","'''\n","conv_net = nn.Sequential(\n","    Conv((32, 1, 31, 31)),     # 画像の大きさ：100x100x1 -> 70x70x32\n","    BatchNorm((32, 70, 70)),\n","    Activation(F.relu),\n","    Dropout(),\n","    Pooling((2, 2),                  # 70x70x32 -> 35x35x32\n","    Conv((64, 32, 21, 21)),     # 35x35x32 -> 15x15x64\n","    BatchNorm((64, 15, 15)),\n","    Activation(F.relu),\n","    Dropout(),\n","    Pooling((2, 2)),                 # 15x15x64 -> 7x7x64\n","    Conv((128, 64, 4, 4)),           # 7x7x64 -> 4x4x128\n","    BatchNorm((128, 4, 4)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                 # 4x4x128 -> 2x2x128\n","    Flatten(),\n","    Dense(2*2*128, 256, F.relu),\n","    Dense(256, 10)\n",")\n","\n","conv_net = nn.Sequential(\n","    Conv((32, 1, 8, 8)),     # 画像の大きさ：40x40x1 -> 33x33x32\n","    Dropout(),\n","    Pooling((3, 3),(3, 3)),                  # 33x33x32 -> 11x11x32\n","    Conv((64, 32, 6, 6)),          # 11x11x32 -> 6x6x64\n","    Conv((128, 64, 3, 3)),           # 6x6x64 -> 4x4x128\n","    Activation(F.relu),\n","    Pooling((2, 2)),                 # 4x4x128 -> 2x2x128\n","    Flatten(),\n","    Dense(2*2*128, 256, F.relu),\n","    Dense(256, 10)\n",")\n","'''\n","conv_net = nn.Sequential(\n","    Conv((20, 1, 5, 5)),     # 画像の大きさ：32x32x1 -> 28x28x20\n","    Pooling((2, 2)),                  # 28x28x20 -> 14x14x20\n","    Conv((20, 20, 5, 5)),          # 14x14x20 -> 10x10x20\n","    Pooling((2, 2)),                  # 10x10x20 -> 5x5x20\n","    Conv((20, 20, 3, 3)),           # 5x5x20 -> 3x3x20\n","    Flatten(),\n","    Dense(3*3*20, 20, F.relu),\n","    Dense(20, 6)\n",")\n","\n","\n","\n","def init_weights(m):  # Heの初期化\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        m.bias.data.fill_(0.0)\n","\n","\n","conv_net.apply(init_weights)\n","\n","\n","n_epochs = 10\n","lr = 0.001\n","device = 'cuda'\n","\n","conv_net.to(device)\n","optimizer = optim.Adam(conv_net.parameters(), lr=lr)\n","loss_function = nn.CrossEntropyLoss()"],"metadata":{"id":"f-fiOgL-mpRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    conv_net.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in dataloader_train:\n","        n_train += t.size()[0]\n","\n","        conv_net.zero_grad()  # 勾配の初期化\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","        t = t.to(device)\n","\n","        y = conv_net.forward(x)  # 順伝播\n","\n","        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        loss.backward()  # 誤差の逆伝播\n","\n","        optimizer.step()  # パラメータの更新\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    conv_net.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","        t = t.to(device)\n","\n","        y = conv_net.forward(x)  # 順伝播\n","\n","        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"metadata":{"id":"G3Y4GhV-mr-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#torch.save(conv_net.state_dict(), 'drive/My Drive/Colab Notebooks/創造性/Identification_persons.pth')"],"metadata":{"id":"k8qWMb8EihcI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_net.state_dict()"],"metadata":{"id":"oFf8utebjaUX"},"execution_count":null,"outputs":[]}]}